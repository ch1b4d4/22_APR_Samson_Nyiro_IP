{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "\n",
    "As a Data Scientist, you work for Hass Consulting Company which is a real estate leader with over 25 years of experience. You have been tasked to study the factors that affect housing prices using the given information on real estate properties that was collected over the past few months. Later onwards, create a model that would allow the company to accurately predict the sale of prices upon being provided with the predictor variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining the Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model that would allow the company to accurately predict the sale of prices upon being provided with the predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Defining the Metric for Success\n",
    "The model will be considered a success when it is able to correctly and accurately predict the sale of prices given the dataset. \n",
    "\n",
    "I look to using 80% as a good target score for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Understanding the context \n",
    "\n",
    "The business would love to predict the house prices to aid its business forecasting and sales in the coming financial years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Recording the Experimental Design\n",
    "1. Perform EDA\n",
    "2. Perform Feature Engineering if necessary\n",
    "3. Check for multicoliinearity\n",
    "4. Build the model\n",
    "5. Perform cross validation\n",
    "6. Calculate the RMSE\n",
    "7. Create the residual plots and assess for heteroskedicity\n",
    "##### Regression Tests to Be Done\n",
    "- Multiple Linear Regression\n",
    "- Quantile Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Data Relevance\n",
    "\n",
    "The data was provided by the Moringa Data Science Program Education Department\n",
    "[http://bit.ly/IndependentProjectWeek7Dataset]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Appropriateness of Data\n",
    "\n",
    "Tests will be carried out to ensure that the data is approprraite for the study or whether additional data needs to be sourced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sb\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy as sp\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Ridge Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Lasso Regression\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Elastic Ridge Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prices[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
    "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15']]\n",
    "y = prices['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Prepare and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation (df):\n",
    "\n",
    "    # df = pd.read_csv(dataset)\n",
    " \n",
    "    # print(f\"\\nShape of the Dataset:{df.head(5)}\")\n",
    "    print(f\"\\n Info of the Dataset:\")\n",
    "    print(f\"\\n {df.info()}\")\n",
    "    print(f\"\\n Shape of the Dataset:{df.shape}\")\n",
    "    print(f\"\\n Description of the Dataset:\")\n",
    "    print(f\"\\n {df.describe()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to run the Quantile Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile (df7):\n",
    "    ## Creating a linear regression model regression on the above dataset\n",
    "    #\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model1 = LinearRegression(fit_intercept = True, normalize = False)\n",
    "    model1.fit(X, y)\n",
    "\n",
    "    y_pred1 = model1.predict(X)\n",
    "\n",
    "    print(\"Mean squared error: {0:.2f}\"\n",
    "        .format(np.mean((y_pred1 - y) ** 2)))\n",
    "    print('Variance score: {0:.2f}'.format(model1.score(X, y)))\n",
    "\n",
    "    # We will use the python package statsmodels for Quantile Regression\n",
    "    #\n",
    "    import statsmodels.formula.api as smf\n",
    "\n",
    "    # Finding the regression coefficients for the conditioned median, 0.5 quantile\n",
    "    #\n",
    "    mod = smf.quantreg('y ~ X', df7)\n",
    "    res = mod.fit(q=.5)\n",
    "\n",
    "    # Then print out the summary of our model\n",
    "    #\n",
    "    print(res.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to run logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit (df6):\n",
    "    sb.heatmap(df6.corr()) \n",
    "\n",
    "# Splitting our dataset\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=100)\n",
    "\n",
    "    # Fitting our model\n",
    "    LogReg = LogisticRegression()\n",
    "    LogReg.fit(X_train, y_train)\n",
    "\n",
    "    # Using our model to make a prediction\n",
    "\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluating the model\n",
    "#\n",
    "\n",
    "    confusion_matric = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_matric)\n",
    "\n",
    "\n",
    "    # Visualizing Confusion Matrix using Heatmap\n",
    "\n",
    "    class_names=[0,1] # name  of classes\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(confusion_matric), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix Plot', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # Confusion Matrix Evaluation Metrics\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot (df7):\n",
    "\n",
    "    # Splitting our dataset\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=100)\n",
    "\n",
    "    # Fitting our model\n",
    "    LogReg = LogisticRegression()\n",
    "    LogReg.fit(X_train, y_train)\n",
    "\n",
    "    # Using our model to make a prediction\n",
    "\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "# ROC Curve\n",
    "\n",
    "    y_pred_proba = LogReg.predict_proba(X_test)[::,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Run a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_reg(df1):\n",
    "    # df1 = pd.read_csv(dataset)\n",
    "\n",
    "    df1.boxplot()\n",
    "    plt.title(\"title\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Points')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Plotting to find any relationship between the variables\n",
    "\n",
    "    df1.plot(x = \"Independent Variable\", y =  \"Dependent Variables\", style='o')\n",
    "    plt.title('Plot for the Indipendent vs Dependent Variables')\n",
    "    plt.xlabel('Score of the Indipendent Variable Studied')\n",
    "    plt.ylabel('Dependent Variable Score')\n",
    "    plt.show()\n",
    "\n",
    "    # Defining the Columns to be used\n",
    "\n",
    "    X = df1.iloc[:, :-1].values\n",
    "    y = df1.iloc[:, 1].values\n",
    "\n",
    "    # Splitting the data\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Training the Algorithm\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train) \n",
    "\n",
    "    # Getting the intercept and slope\n",
    "\n",
    "    print(\"\\nIntercept: \", regressor.intercept_)   \n",
    "    print(\"\\nRegressor\", regressor.coef_)\n",
    "\n",
    "    # Making Predictions\n",
    "\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    df12 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "    print(f\"\\n{df12}\")\n",
    "\n",
    "    # Evaluating the Algorithm\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    print('\\nMean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('\\nMean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('\\nRoot Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to run a Mutiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutiple_line(df6):\n",
    "    plt.figure(figsize = (10,8))\n",
    "    plt.title(\"Correlation Plot\")\n",
    "    sb.heatmap(df6.corr()) \n",
    "\n",
    "    # Dividing our data into training and test sets\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training the Algorithm\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])\n",
    "    print(f\"{coeff_df}\")\n",
    "\n",
    "    # Making Predictions\n",
    "\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # To compare the actual output values for X_test with the predicted values\n",
    "    # \n",
    "    df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "    print(f\"\\n{df}\")\n",
    "\n",
    "    # Evaluating the Algorithm\n",
    "\n",
    "    from sklearn import metrics\n",
    "    print('\\nMean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('\\nMean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('\\nRoot Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yiIOWylE2yT"
   },
   "source": [
    "#### Functions to check for the Residual plots and heteroskedasticity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_check (df2):\n",
    "\n",
    "    # df2 = pd.read_csv(dataset)\n",
    "    \n",
    "    # X = df2.iloc[:, :-1].values\n",
    "    # y = df2.iloc[:, 1].values\n",
    "\n",
    "\n",
    "    X_train, X_test, admit_train, admit_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, admit_train)\n",
    "\n",
    "    # This is our prediction for admission based on our model\n",
    "    admit_predict = regressor.predict(X_test)\n",
    "\n",
    "    # We now create the residual by substracting the test value from the predicted \n",
    "    # value for each row in our dataset\n",
    "\n",
    "    residuals = np.subtract(admit_predict, admit_test)\n",
    "\n",
    "    # Let's describe our residual:\n",
    "    pd.DataFrame(residuals).describe()\n",
    "\n",
    "    print(f\"\\n residual Mean: {residuals.mean() }\")\n",
    "\n",
    "    plt.scatter(admit_predict, residuals, color='black')\n",
    "    plt.title(\"Residual Plot\")\n",
    "    plt.ylabel('residual')\n",
    "    plt.xlabel('fitted values')\n",
    "    plt.axhline(y= residuals.mean(), color='red', linewidth=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to check for heteroskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heteroskedasticity(df3):\n",
    "\n",
    "    # df3 = pd.read_csv(dataset)\n",
    "\n",
    "    # Define the Columns to be used in this test\n",
    "\n",
    "    # X = df3.iloc[:, :-1].values\n",
    "    # y = df3.iloc[:, 1].values\n",
    "\n",
    "    # Train the Dataset\n",
    "\n",
    "    X_train, X_test, admit_train, admit_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, admit_train)\n",
    "\n",
    "    admit_predict = regressor.predict(X_test)\n",
    "\n",
    "    # We now create the residual by substracting the test value from the predicted \n",
    "    # value for each row in our dataset\n",
    "\n",
    "    residuals = np.subtract(admit_predict, admit_test)\n",
    "    test_result, p_value = sp.stats.bartlett(admit_predict, residuals)\n",
    "\n",
    "    # To interpret the results we must also compute a critical value of the chi squared distribution\n",
    "    degree_of_freedom = len(admit_predict)-1\n",
    "    probability = 1 - p_value\n",
    "\n",
    "    critical_value = sp.stats.chi2.ppf(probability, degree_of_freedom)\n",
    "    print(critical_value)\n",
    "\n",
    "    # \n",
    "    # If the test_result is greater than the critical value, then we reject our null\n",
    "    # hypothesis. This would mean that there are patterns to the variance of the data\n",
    "\n",
    "    # Otherwise, we can identify no patterns, and we accept the null hypothesis that \n",
    "    # the variance is homogeneous across our data\n",
    "\n",
    "    if (test_result > critical_value):\n",
    "      print('the variances are unequal, and the model should be reassessed')\n",
    "    else:\n",
    "      print('the variances are homogeneous!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Calculate the R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(df4):\n",
    "\n",
    "    r2 = r2_score(X,y)\n",
    "\n",
    "    print(f\"r2 score for our model is: {r2_score(X,y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Run Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge (df8):\n",
    "        # Creating our baseline regression model\n",
    "    # This is a model that has no regularization to it\n",
    "    # \n",
    "    regression = LinearRegression()\n",
    "    regression.fit(X,y)\n",
    "    first_model = (mean_squared_error(y_true=y,y_pred=regression.predict(X)))\n",
    "    print(\"The MSE for Base Model:\", first_model)\n",
    "\n",
    "        # Creating the Ridge Model\n",
    "    ridge = Ridge(normalize=True)\n",
    "    search = GridSearchCV(estimator=ridge,param_grid={'alpha':np.logspace(-5,2,8)},scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Run the Lasso Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso (df9):\n",
    "        # Standadizing our features\n",
    "    #\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # X = scaler.transform(X)\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    \n",
    "\n",
    "        # Creating lasso regression with alpha value\n",
    "    regr = Lasso(alpha=0.5)\n",
    "\n",
    "    # Fitting the linear regression\n",
    "    model = regr.fit(X_std, y)\n",
    "\n",
    "\n",
    "    # Importing linear models\n",
    "    # \n",
    "    from sklearn import linear_model\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # Creating lasso object\n",
    "    # \n",
    "    lasso = linear_model.Lasso() \n",
    "\n",
    "    # Fitting the models\n",
    "    # \n",
    "    lasso.fit(X, y) \n",
    "\n",
    "    # Print scores, MSE, and coefficients\n",
    "    # \n",
    "    print(\"\\nlasso score:\", lasso.score(X, y)) \n",
    "    print(\"\\nlasso MSE:\", mean_squared_error(y, lasso.predict(X))) \n",
    "    print(\"\\nlasso coef:\", lasso.coef_) \n",
    "\n",
    "\n",
    "\n",
    "    # Making necessary imports, split data into training and test sets, and choose a set of parameters \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "    parameters = {'alpha': np.concatenate((np.arange(0.1,2,0.1), np.arange(2, 5, 0.5), np.arange(5, 25, 1)))}\n",
    "\n",
    "    linear = linear_model.LinearRegression()\n",
    "    lasso = linear_model.Lasso() \n",
    "    gridlasso = GridSearchCV(lasso, parameters, scoring ='r2') \n",
    "\n",
    "    # Fitting models and print the best parameters, R-squared scores, MSE, and coefficients\n",
    "    gridlasso.fit(X_train, y_train) \n",
    "    linear.fit(X_train, y_train) \n",
    "    print(\"\\nlasso best parameters:\", gridlasso.best_params_) \n",
    "    print(\"\\nlasso score:\", gridlasso.score(X_test, y_test))\n",
    "    print(\"\\nlinear score:\", linear.score(X_test, y_test)) \n",
    "    print(\"\\nlasso MSE:\", mean_squared_error(y_test, gridlasso.predict(X_test)))\n",
    "    print(\"\\nlinear MSE:\", mean_squared_error(y_test, linear.predict(X_test))) \n",
    "    print(\"\\nlasso best estimator coef:\", gridlasso.best_estimator_.coef_)\n",
    "    print(\"\\nlinear coef:\", linear.coef_)\n",
    "\n",
    "\n",
    "        # Importing library for visualization\n",
    "    #\n",
    "    import matplotlib.pyplot as plt\n",
    "    coefsLasso = [] \n",
    "\n",
    "    # Building Lasso for 200 values of alpha and write the coefficients into array\n",
    "    # \n",
    "    alphasLasso = np.arange (0, 20, 0.1) \n",
    "    for i in range(200):\n",
    "        lasso = linear_model.Lasso(alpha=alphasLasso[i])\n",
    "        lasso.fit(X_train, y_train)\n",
    "        coefsLasso.append(lasso.coef_) \n",
    "\n",
    "    # Building Lasso coefficient plots\n",
    "    # \n",
    "    plt.figure(figsize = (16,7))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(alphasLasso, coefsLasso)\n",
    "    plt.title('Lasso coefficients')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('coefs')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Function to Run the Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic (df10):\n",
    "    # Creating our linear regression model for the purpose of comparison\n",
    "    # \n",
    "    regression=LinearRegression()\n",
    "    regression.fit(X,y)\n",
    "    first_model=(mean_squared_error(y_true=y,y_pred=regression.predict(X)))\n",
    "    print(\"The MSE for Base Model:\", first_model) \n",
    "\n",
    "    coef_dict_baseline = {}\n",
    "    for coef, feat in zip(regression.coef_,X.columns):\n",
    "        coef_dict_baseline[feat] = coef\n",
    "        coef_dict_baseline\n",
    "\n",
    "\n",
    "    # \n",
    "    elastic=ElasticNet(normalize=True)\n",
    "    search=GridSearchCV(estimator=elastic,param_grid={'alpha':np.logspace(-5,2,8),'l1_ratio':[.2,.4,.6,.8]},scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)\n",
    "\n",
    "    # We will now fit our model and display the best parameters and the best results we can get with that setup.\n",
    "    # \n",
    "    search.fit(X,y)\n",
    "    search.best_params_\n",
    "    abs(search.best_score_)\n",
    "\n",
    "    elastic=ElasticNet(normalize=True,alpha=0.001,l1_ratio=0.75)\n",
    "    elastic.fit(X,y)\n",
    "    second_model=(mean_squared_error(y_true=y,y_pred=elastic.predict(X)))\n",
    "    print(\"The MSE for the Second Model:\",second_model)\n",
    "\n",
    "    # Below are the coefficients\n",
    "    # \n",
    "    coef_dict_baseline = {}\n",
    "    for coef, feat in zip(elastic.coef_,X.columns):\n",
    "        coef_dict_baseline[feat] = coef\n",
    "    coef_dict_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation of the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before reading our dataset, we would like to ensure all columns are visible \n",
    "# ---\n",
    "#  \n",
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv('http://bit.ly/IndependentProjectWeek7Dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Info of the Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   price          21613 non-null  float64\n",
      " 2   bedrooms       21613 non-null  int64  \n",
      " 3   bathrooms      21613 non-null  float64\n",
      " 4   sqft_living    21613 non-null  int64  \n",
      " 5   sqft_lot       21613 non-null  int64  \n",
      " 6   floors         21613 non-null  float64\n",
      " 7   waterfront     21613 non-null  int64  \n",
      " 8   view           21613 non-null  int64  \n",
      " 9   condition      21613 non-null  int64  \n",
      " 10  grade          21613 non-null  int64  \n",
      " 11  sqft_above     21613 non-null  int64  \n",
      " 12  sqft_basement  21613 non-null  int64  \n",
      " 13  yr_built       21613 non-null  int64  \n",
      " 14  yr_renovated   21613 non-null  int64  \n",
      " 15  zipcode        21613 non-null  int64  \n",
      " 16  lat            21613 non-null  float64\n",
      " 17  long           21613 non-null  float64\n",
      " 18  sqft_living15  21613 non-null  int64  \n",
      " 19  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15)\n",
      "memory usage: 3.3 MB\n",
      "\n",
      " None\n",
      "\n",
      " Shape of the Dataset:(21613, 20)\n",
      "\n",
      " Description of the Dataset:\n",
      "\n",
      "                  id         price      bedrooms     bathrooms   sqft_living  \\\n",
      "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
      "mean   4.580302e+09  5.401822e+05      3.370842      2.114757   2079.899736   \n",
      "std    2.876566e+09  3.673622e+05      0.930062      0.770163    918.440897   \n",
      "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
      "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
      "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
      "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
      "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
      "\n",
      "           sqft_lot        floors    waterfront          view     condition  \\\n",
      "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
      "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
      "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
      "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
      "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
      "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
      "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
      "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
      "\n",
      "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
      "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
      "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
      "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
      "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
      "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
      "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
      "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
      "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
      "\n",
      "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
      "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
      "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
      "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
      "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
      "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
      "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
      "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
      "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0      7129300520  221900.0         3       1.00         1180      5650   \n",
       "1      6414100192  538000.0         3       2.25         2570      7242   \n",
       "2      5631500400  180000.0         2       1.00          770     10000   \n",
       "3      2487200875  604000.0         4       3.00         1960      5000   \n",
       "4      1954400510  510000.0         3       2.00         1680      8080   \n",
       "...           ...       ...       ...        ...          ...       ...   \n",
       "21608   263000018  360000.0         3       2.50         1530      1131   \n",
       "21609  6600060120  400000.0         4       2.50         2310      5813   \n",
       "21610  1523300141  402101.0         2       0.75         1020      1350   \n",
       "21611   291310100  400000.0         3       2.50         1600      2388   \n",
       "21612  1523300157  325000.0         2       0.75         1020      1076   \n",
       "\n",
       "       floors  waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "0         1.0           0     0          3      7        1180              0   \n",
       "1         2.0           0     0          3      7        2170            400   \n",
       "2         1.0           0     0          3      6         770              0   \n",
       "3         1.0           0     0          5      7        1050            910   \n",
       "4         1.0           0     0          3      8        1680              0   \n",
       "...       ...         ...   ...        ...    ...         ...            ...   \n",
       "21608     3.0           0     0          3      8        1530              0   \n",
       "21609     2.0           0     0          3      8        2310              0   \n",
       "21610     2.0           0     0          3      7        1020              0   \n",
       "21611     2.0           0     0          3      8        1600              0   \n",
       "21612     2.0           0     0          3      7        1020              0   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0          1955             0    98178  47.5112 -122.257           1340   \n",
       "1          1951          1991    98125  47.7210 -122.319           1690   \n",
       "2          1933             0    98028  47.7379 -122.233           2720   \n",
       "3          1965             0    98136  47.5208 -122.393           1360   \n",
       "4          1987             0    98074  47.6168 -122.045           1800   \n",
       "...         ...           ...      ...      ...      ...            ...   \n",
       "21608      2009             0    98103  47.6993 -122.346           1530   \n",
       "21609      2014             0    98146  47.5107 -122.362           1830   \n",
       "21610      2009             0    98144  47.5944 -122.299           1020   \n",
       "21611      2004             0    98027  47.5345 -122.069           1410   \n",
       "21612      2008             0    98144  47.5941 -122.299           1020   \n",
       "\n",
       "       sqft_lot15  \n",
       "0            5650  \n",
       "1            7639  \n",
       "2            8062  \n",
       "3            5000  \n",
       "4            7503  \n",
       "...           ...  \n",
       "21608        1509  \n",
       "21609        7200  \n",
       "21610        2007  \n",
       "21611        1287  \n",
       "21612        1357  \n",
       "\n",
       "[21613 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparation(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Total, Percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in the dataset demographic data.\n",
    " \n",
    "# Creating a function to check\n",
    "def missing_values(data):\n",
    " \n",
    " # identifying the missing values from the demographic data dataset\n",
    " #\n",
    " miss = data.isnull().sum().sort_values(ascending = False)\n",
    " # finding the percentage of missing values\n",
    " percentage = (data.isnull().sum() / len(data)).sort_values(ascending = False)\n",
    " # storing  total missing values in percentage in dataframe\n",
    " #\n",
    " missing_data = pd.DataFrame({'Total' : miss, 'Percentage' : percentage})\n",
    " #if the percentage is 0, indicates no missing values hence removed\n",
    " #\n",
    " missing_data.drop(missing_data[missing_data['Percentage'] == 0].index, inplace = True)\n",
    " \n",
    " return missing_data\n",
    " \n",
    "missing_values(prices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>1825069031</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2410</td>\n",
       "      <td>8447</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2060</td>\n",
       "      <td>350</td>\n",
       "      <td>1936</td>\n",
       "      <td>1980</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6499</td>\n",
       "      <td>-122.088</td>\n",
       "      <td>2520</td>\n",
       "      <td>14789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>6308000010</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2290</td>\n",
       "      <td>5089</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2290</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5443</td>\n",
       "      <td>-122.172</td>\n",
       "      <td>2290</td>\n",
       "      <td>7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20054</th>\n",
       "      <td>8648900110</td>\n",
       "      <td>555000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1940</td>\n",
       "      <td>3211</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5644</td>\n",
       "      <td>-122.093</td>\n",
       "      <td>1880</td>\n",
       "      <td>3078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "3951   1825069031  550000.0         4       1.75         2410      8447   \n",
       "14983  6308000010  585000.0         3       2.50         2290      5089   \n",
       "20054  8648900110  555000.0         3       2.50         1940      3211   \n",
       "\n",
       "       floors  waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "3951      2.0           0     3          4      8        2060            350   \n",
       "14983     2.0           0     0          3      9        2290              0   \n",
       "20054     2.0           0     0          3      8        1940              0   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "3951       1936          1980    98074  47.6499 -122.088           2520   \n",
       "14983      2001             0    98006  47.5443 -122.172           2290   \n",
       "20054      2009             0    98027  47.5644 -122.093           1880   \n",
       "\n",
       "       sqft_lot15  \n",
       "3951        14789  \n",
       "14983        7984  \n",
       "20054        3078  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check For Duplicate values\n",
    "# occurrence based on all columns\n",
    "duplicate = prices[prices.duplicated()]\n",
    " \n",
    "print(\"Duplicate Rows :\")\n",
    " \n",
    "# Print the resultant Dataframe\n",
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset shows an occurance of duplicate values but a closer investigation proves otherwise hence no action to be taken further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's check for outliers in the dataset using boxplot and give it a title and label\n",
    "\n",
    "# let's create a function to plot the boxplot\n",
    "def plot_boxplot(data,title,label):\n",
    "    data.boxplot()\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Points')\n",
    "    plt.show()\n",
    "\n",
    "plot_boxplot(prices, 'Boxplot of Outliers', 'Points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No outliers seem to be present in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/la/Library/Python/3.8/lib/python/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          feature       VIF\n",
      "0              id  3.632659\n",
      "1           price  3.330835\n",
      "2        bedrooms  1.673248\n",
      "3       bathrooms  3.375022\n",
      "4     sqft_living       inf\n",
      "5        sqft_lot  2.104736\n",
      "6          floors  1.951202\n",
      "7      waterfront  1.266535\n",
      "8            view  1.460071\n",
      "9       condition  1.228050\n",
      "10          grade  3.706482\n",
      "11     sqft_above       inf\n",
      "12  sqft_basement       inf\n",
      "13       yr_built  2.268879\n",
      "14   yr_renovated  1.146372\n",
      "15        zipcode  0.505574\n",
      "16            lat  1.351917\n",
      "17           long  1.832974\n",
      "18  sqft_living15  2.889117\n",
      "19     sqft_lot15  2.145441\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "  \n",
    "  \n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = prices.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(prices.values, i)\n",
    "                          for i in range(len(prices.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our values have a low VIF score hence showing that there is low corelation between the variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.401822e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.673622e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.401822e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.673622e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the descriptive statistics\n",
    "# ---\n",
    "\n",
    "prices.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
       "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our attributes and labels\n",
    "# ---\n",
    "#\n",
    "X = prices[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
    "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15']]\n",
    "y = prices['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " residual Mean: 4626.5218534608775\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "residual_check(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the residuals are all plotted close to the mean hence showing the appropriatness of this dataset to run the test and regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heteroskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "the variances are homogeneous!\n"
     ]
    }
   ],
   "source": [
    "heteroskedasticity(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Variables are Homogenous hence appropriate for a regression Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R2 Coeffecient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6997525539851861 0.6995022782591387\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "yhat = model.predict(X)\n",
    "SS_Residual = sum((y-yhat)**2)       \n",
    "SS_Total = sum((y-np.mean(y))**2)     \n",
    "r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "print (r_squared, adjusted_r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance in this model is explained by over 70% thus showing how appropriate it is to run the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Mutiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Coefficient\n",
      "bedrooms       -34700.723276\n",
      "bathrooms       39453.777987\n",
      "sqft_living       112.667741\n",
      "sqft_lot            0.175770\n",
      "floors           7422.747673\n",
      "waterfront     605764.113766\n",
      "view            52800.675583\n",
      "condition       26193.691361\n",
      "grade           93684.336063\n",
      "sqft_above         72.833023\n",
      "sqft_basement      39.834718\n",
      "yr_built        -2609.264147\n",
      "yr_renovated       20.121682\n",
      "zipcode          -567.605311\n",
      "lat            604949.838451\n",
      "long          -222616.017356\n",
      "sqft_living15      24.242701\n",
      "sqft_lot15         -0.467518\n",
      "\n",
      "          Actual     Predicted\n",
      "17384   297000.0  3.783754e+05\n",
      "722    1580000.0  1.540515e+06\n",
      "2680    562100.0  5.445618e+05\n",
      "18754   631500.0  5.779767e+05\n",
      "14554   780000.0  9.803160e+05\n",
      "...          ...           ...\n",
      "5427    844000.0  9.661871e+05\n",
      "16547   335500.0  4.614823e+05\n",
      "4585    369950.0  3.597607e+05\n",
      "17762   300000.0  2.068983e+05\n",
      "16323   575950.0  4.336015e+05\n",
      "\n",
      "[4323 rows x 2 columns]\n",
      "\n",
      "Mean Absolute Error: 122292.14383822103\n",
      "\n",
      "Mean Squared Error: 36326416754.03399\n",
      "\n",
      "Root Mean Squared Error: 190594.90222467648\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mutiple_line(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output gives us a couple of insights:\n",
    "- The grade of the building and whether it is a waterfront property is one of the biggest influences to the final price of the property\n",
    "- The RMSE value of 190594.90222467648 is less than 10% of the mean of the dependant value hence showing that the model is reliable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quantile Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 40518022074.28\n",
      "Variance score: 0.70\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Pseudo R-squared:               0.4728\n",
      "Model:                       QuantReg   Bandwidth:                   1.946e+04\n",
      "Method:                 Least Squares   Sparsity:                    2.628e+05\n",
      "Date:                Fri, 22 Apr 2022   No. Observations:                21613\n",
      "Time:                        16:20:09   Df Residuals:                    21595\n",
      "                                        Df Model:                           17\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -140.8744      4.144    -33.996      0.000    -148.997    -132.752\n",
      "X[0]       -2.143e+04   1233.018    -17.383      0.000   -2.39e+04    -1.9e+04\n",
      "X[1]        2.885e+04   2124.164     13.583      0.000    2.47e+04     3.3e+04\n",
      "X[2]          66.8088      1.481     45.112      0.000      63.906      69.712\n",
      "X[3]           0.2079      0.031      6.651      0.000       0.147       0.269\n",
      "X[4]        3.525e+04   2311.911     15.246      0.000    3.07e+04    3.98e+04\n",
      "X[5]        2.111e+05   1.13e+04     18.623      0.000    1.89e+05    2.33e+05\n",
      "X[6]        5.522e+04   1389.425     39.742      0.000    5.25e+04    5.79e+04\n",
      "X[7]        2.499e+04   1517.067     16.470      0.000     2.2e+04     2.8e+04\n",
      "X[8]        7.978e+04   1400.650     56.961      0.000     7.7e+04    8.25e+04\n",
      "X[9]          34.4272      1.461     23.565      0.000      31.564      37.291\n",
      "X[10]         32.3943      1.713     18.909      0.000      29.036      35.752\n",
      "X[11]      -2057.9843     44.397    -46.354      0.000   -2145.005   -1970.964\n",
      "X[12]         17.6563      2.380      7.417      0.000      12.991      22.322\n",
      "X[13]       -279.5135     11.637    -24.019      0.000    -302.324    -256.703\n",
      "X[14]       5.493e+05   7006.849     78.391      0.000    5.36e+05    5.63e+05\n",
      "X[15]      -3.945e+04   8526.987     -4.627      0.000   -5.62e+04   -2.27e+04\n",
      "X[16]         36.8205      2.214     16.630      0.000      32.481      41.160\n",
      "X[17]         -0.2516      0.048     -5.264      0.000      -0.345      -0.158\n",
      "==============================================================================\n",
      "\n",
      "The condition number is large, 8.14e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/la/Library/Python/3.8/lib/python/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "quantile(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for Base Model: 40518022074.275925\n"
     ]
    }
   ],
   "source": [
    "ridge(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for Base Model: 40518022074.275925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41016657649.82225"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     # Creating the Ridge Model\n",
    "regression = LinearRegression()\n",
    "regression.fit(X,y)\n",
    "first_model = (mean_squared_error(y_true=y,y_pred=regression.predict(X)))\n",
    "print(\"The MSE for Base Model:\", first_model)\n",
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "search = GridSearchCV(estimator=ridge,param_grid={'alpha':np.logspace(-5,2,8)},scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)\n",
    "\n",
    "search.fit(X,y)\n",
    "search.best_params_\n",
    "{'alpha': 0.01}\n",
    "abs(search.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40524344765.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/la/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# We can confirm this by fitting our model with the ridge information and finding the mean squared error below\n",
    "#\n",
    "ridge = Ridge(normalize=True,alpha=0.01)\n",
    "ridge.fit(X,y)\n",
    "second_model = (mean_squared_error(y_true=y,y_pred=ridge.predict(X)))\n",
    "print(second_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': -35797.78526878027,\n",
       " 'price': 41166.76100968799,\n",
       " 'bedrooms': 110.51388750604916,\n",
       " 'bathrooms': 0.12840424994483035,\n",
       " 'sqft_living': 6695.157538716981,\n",
       " 'sqft_lot': 583016.9475137593,\n",
       " 'floors': 52934.07499962661,\n",
       " 'waterfront': 26412.954334727685,\n",
       " 'view': 95985.79230523002,\n",
       " 'condition': 70.82712642204363,\n",
       " 'grade': 39.68676095797481,\n",
       " 'sqft_above': -2622.410499457613,\n",
       " 'sqft_basement': 19.824180497913297,\n",
       " 'yr_built': -582.5716677591586,\n",
       " 'yr_renovated': 602825.2080907875,\n",
       " 'zipcode': -214960.62365184783,\n",
       " 'lat': 21.67584906828925,\n",
       " 'long': -0.3824610304036469}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "coef_dict_baseline = {}\n",
    "for coef, feat in zip(regression.coef_,prices.columns):\n",
    "    coef_dict_baseline[feat] = coef\n",
    "coef_dict_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lasso score: 0.6997525517115606\n",
      "\n",
      "lasso MSE: 40518022381.09862\n",
      "\n",
      "lasso coef: [-3.57967295e+04  4.11634202e+04  2.85032232e+02  1.28366433e-01\n",
      "  6.69413092e+03  5.82865467e+05  5.29391889e+04  2.64095267e+04\n",
      "  9.59884515e+04 -1.03690658e+02 -1.34826318e+02 -2.62253879e+03\n",
      "  1.98251341e+01 -5.82432859e+02  6.02760439e+05 -2.14871152e+05\n",
      "  2.16729611e+01 -3.82510071e-01]\n",
      "\n",
      "lasso best parameters: {'alpha': 21.0}\n",
      "\n",
      "lasso score: 0.7097090163878486\n",
      "\n",
      "linear score: 0.7097371661736279\n",
      "\n",
      "lasso MSE: 41211703110.60994\n",
      "\n",
      "linear MSE: 41207706773.556244\n",
      "\n",
      "lasso best estimator coef: [-3.69884742e+04  3.62275459e+04  2.84236867e+02  1.41883588e-01\n",
      "  1.13651350e+04  5.50535029e+05  5.18910691e+04  2.90625912e+04\n",
      "  9.62675194e+04 -1.03477736e+02 -1.35504662e+02 -2.62472207e+03\n",
      "  1.75862943e+01 -5.85090613e+02  6.01343447e+05 -2.15440293e+05\n",
      "  2.44235201e+01 -3.60147101e-01]\n",
      "\n",
      "linear coef: [-3.70140238e+04  3.63014673e+04  1.09794156e+02  1.42623119e-01\n",
      "  1.13874494e+04  5.53581104e+05  5.17853823e+04  2.91315400e+04\n",
      "  9.62054553e+04  7.09595537e+01  3.88346019e+01 -2.62208182e+03\n",
      "  1.75620446e+01 -5.87991991e+02  6.02698803e+05 -2.17300930e+05\n",
      "  2.44827526e+01 -3.59080657e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Elastic Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for Base Model: 40518022074.275925\n",
      "The MSE for the Second Model: 79376555016.66553\n"
     ]
    }
   ],
   "source": [
    "elastic(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40518022074.275925\n"
     ]
    }
   ],
   "source": [
    "# Creating our linear regression model for the purpose of comparison\n",
    "# \n",
    "from pydataset import data\n",
    "\n",
    "regression=LinearRegression()\n",
    "regression.fit(X,y)\n",
    "first_model=(mean_squared_error(y_true=y,y_pred=regression.predict(X)))\n",
    "print(first_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bedrooms': -35797.78526878027,\n",
       " 'bathrooms': 41166.76100968799,\n",
       " 'sqft_living': 110.51388750604916,\n",
       " 'sqft_lot': 0.12840424994483035,\n",
       " 'floors': 6695.157538716981,\n",
       " 'waterfront': 583016.9475137593,\n",
       " 'view': 52934.07499962661,\n",
       " 'condition': 26412.954334727685,\n",
       " 'grade': 95985.79230523002,\n",
       " 'sqft_above': 70.82712642204363,\n",
       " 'sqft_basement': 39.68676095797481,\n",
       " 'yr_built': -2622.410499457613,\n",
       " 'yr_renovated': 19.824180497913297,\n",
       " 'zipcode': -582.5716677591586,\n",
       " 'lat': 602825.2080907875,\n",
       " 'long': -214960.62365184783,\n",
       " 'sqft_living15': 21.67584906828925,\n",
       " 'sqft_lot15': -0.3824610304036469}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below are the coefficients of this first model. We use a for loop to go through \n",
    "# the model and the zip function to combine the two columns.\n",
    "# \n",
    "coef_dict_baseline = {}\n",
    "for coef, feat in zip(regression.coef_,X.columns):\n",
    "    coef_dict_baseline[feat] = coef\n",
    "coef_dict_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net Model\n",
    "# Elastic net, just like ridge and lasso regression, requires normalize data. \n",
    "# This argument  is set inside the ElasticNet function. \n",
    "# The second thing we need to do is create our grid.\n",
    "# \n",
    "elastic=ElasticNet(normalize=True)\n",
    "search=GridSearchCV(estimator=elastic,param_grid={'alpha':np.logspace(-5,2,8),'l1_ratio':[.2,.4,.6,.8]},scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41058369186.64148"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now fit our model and display the best parameters and the best results we can get with that setup.\n",
    "# \n",
    "search.fit(X,y)\n",
    "search.best_params_\n",
    "abs(search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79376555016.66553\n"
     ]
    }
   ],
   "source": [
    "elastic=ElasticNet(normalize=True,alpha=0.001,l1_ratio=0.75)\n",
    "elastic.fit(X,y)\n",
    "second_model=(mean_squared_error(y_true=y,y_pred=elastic.predict(X)))\n",
    "print(second_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bedrooms': 9155.504009716382,\n",
       " 'bathrooms': 23091.814427233778,\n",
       " 'sqft_living': 28.799709870733352,\n",
       " 'sqft_lot': 0.058884694865293664,\n",
       " 'floors': 14344.85611049671,\n",
       " 'waterfront': 143890.34582180186,\n",
       " 'view': 21942.804290075466,\n",
       " 'condition': 5771.699965611121,\n",
       " 'grade': 22210.389114051002,\n",
       " 'sqft_above': 26.88253093636235,\n",
       " 'sqft_basement': 29.913482419991606,\n",
       " 'yr_built': -116.48434589869713,\n",
       " 'yr_renovated': 14.761443494182139,\n",
       " 'zipcode': -5.75846185452919,\n",
       " 'lat': 117967.60514689352,\n",
       " 'long': -19353.74153969671,\n",
       " 'sqft_living15': 31.194117802574013,\n",
       " 'sqft_lot15': 0.06329940772824336}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below are the coefficients\n",
    "# \n",
    "coef_dict_baseline = {}\n",
    "for coef, feat in zip(elastic.coef_,X.columns):\n",
    "    coef_dict_baseline[feat] = coef\n",
    "coef_dict_baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
